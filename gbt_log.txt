2018-06-06 13:40:48 WARN  Utils:66 - Your hostname, 056207lab02l resolves to a loopback address: 127.0.1.1; using 134.197.42.27 instead (on interface enp9s0)
2018-06-06 13:40:48 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2018-06-06 13:40:48 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-06-06 13:40:48 INFO  SparkContext:54 - Running Spark version 2.3.0
2018-06-06 13:40:48 INFO  SparkContext:54 - Submitted application: gb_tree_regression_transform_no_recursive_logsinh.py
2018-06-06 13:40:48 INFO  SecurityManager:54 - Changing view acls to: rwu
2018-06-06 13:40:48 INFO  SecurityManager:54 - Changing modify acls to: rwu
2018-06-06 13:40:48 INFO  SecurityManager:54 - Changing view acls groups to: 
2018-06-06 13:40:48 INFO  SecurityManager:54 - Changing modify acls groups to: 
2018-06-06 13:40:48 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(rwu); groups with view permissions: Set(); users  with modify permissions: Set(rwu); groups with modify permissions: Set()
2018-06-06 13:40:49 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 45059.
2018-06-06 13:40:49 INFO  SparkEnv:54 - Registering MapOutputTracker
2018-06-06 13:40:49 INFO  SparkEnv:54 - Registering BlockManagerMaster
2018-06-06 13:40:49 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-06-06 13:40:49 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2018-06-06 13:40:49 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-e9121eed-1237-4df5-8378-025826f01b28
2018-06-06 13:40:49 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2018-06-06 13:40:49 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2018-06-06 13:40:49 INFO  log:192 - Logging initialized @1402ms
2018-06-06 13:40:49 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2018-06-06 13:40:49 INFO  Server:414 - Started @1464ms
2018-06-06 13:40:49 INFO  AbstractConnector:278 - Started ServerConnector@16f8b473{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-06-06 13:40:49 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2018-06-06 13:40:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67ce9163{/jobs,null,AVAILABLE,@Spark}
2018-06-06 13:40:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1b07658d{/jobs/json,null,AVAILABLE,@Spark}
2018-06-06 13:40:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bc9fe83{/jobs/job,null,AVAILABLE,@Spark}
2018-06-06 13:40:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@21d81bf8{/jobs/job/json,null,AVAILABLE,@Spark}
2018-06-06 13:40:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1532943{/stages,null,AVAILABLE,@Spark}
2018-06-06 13:40:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@759af20c{/stages/json,null,AVAILABLE,@Spark}
2018-06-06 13:40:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@659a7946{/stages/stage,null,AVAILABLE,@Spark}
2018-06-06 13:40:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3e550a2a{/stages/stage/json,null,AVAILABLE,@Spark}
2018-06-06 13:40:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@8b304ef{/stages/pool,null,AVAILABLE,@Spark}
2018-06-06 13:40:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@69e0ae36{/stages/pool/json,null,AVAILABLE,@Spark}
2018-06-06 13:40:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@19e49e68{/storage,null,AVAILABLE,@Spark}
2018-06-06 13:40:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@ff6d324{/storage/json,null,AVAILABLE,@Spark}
2018-06-06 13:40:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1ff22a49{/storage/rdd,null,AVAILABLE,@Spark}
2018-06-06 13:40:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@738fa69f{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-06-06 13:40:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4e257158{/environment,null,AVAILABLE,@Spark}
2018-06-06 13:40:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7773e44b{/environment/json,null,AVAILABLE,@Spark}
2018-06-06 13:40:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@795d288e{/executors,null,AVAILABLE,@Spark}
2018-06-06 13:40:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7768d264{/executors/json,null,AVAILABLE,@Spark}
2018-06-06 13:40:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@12a2c260{/executors/threadDump,null,AVAILABLE,@Spark}
2018-06-06 13:40:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7a1b2dc3{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-06-06 13:40:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6a127356{/static,null,AVAILABLE,@Spark}
2018-06-06 13:40:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5b70d3ca{/,null,AVAILABLE,@Spark}
2018-06-06 13:40:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3eb8c254{/api,null,AVAILABLE,@Spark}
2018-06-06 13:40:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7f56f32e{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-06-06 13:40:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cc19f9e{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-06-06 13:40:49 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://134.197.42.27:4040
Traceback (most recent call last):
  File "/home/rwu/Desktop/hydrologic_model_accuracy_improvement/ml_moduel/gb_tree_regression_transform_no_recursive_logsinh.py", line 101, in <module>
    sc = SparkContext()
  File "/home/rwu/Desktop/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/context.py", line 118, in __init__
  File "/home/rwu/Desktop/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/context.py", line 180, in _do_init
  File "/home/rwu/Desktop/spark-2.3.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/context.py", line 270, in _initialize_context
  File "/home/rwu/Desktop/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py", line 1426, in __call__
  File "/home/rwu/Desktop/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py", line 908, in send_command
  File "/home/rwu/Desktop/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py", line 1055, in send_command
  File "/usr/lib/python2.7/socket.py", line 451, in readline
    data = self._sock.recv(self._rbufsize)
KeyboardInterrupt
2018-06-06 13:40:49 INFO  DiskBlockManager:54 - Shutdown hook called
2018-06-06 13:40:49 INFO  ShutdownHookManager:54 - Shutdown hook called
2018-06-06 13:40:49 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-c1b4c6ca-10fa-4a55-996f-e5878db66b7d
2018-06-06 13:40:49 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-a4b827e8-cf38-4fab-b4f8-c1e564bd1896/userFiles-cc8359b1-359f-47c9-814e-ff7e6e699511
2018-06-06 13:40:49 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-a4b827e8-cf38-4fab-b4f8-c1e564bd1896
